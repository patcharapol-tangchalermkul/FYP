{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6154d34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "import sklearn.model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import abstract_gradient_training as agt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a373f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Initialise the halfmoons training data.\"\"\"\n",
    "seed = 0\n",
    "batchsize = 10000  # number of samples per batch\n",
    "test_size = 5000\n",
    "n_users = 250\n",
    "n_batches = 1  # number of batches per epoch\n",
    "n_epochs = 10  # number of epochs\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "# load the dataset\n",
    "x, y = sklearn.datasets.make_moons(noise=0.1, n_samples=n_batches*batchsize + test_size, random_state=seed)\n",
    "# to make it easier to train, we'll space the moons out a bit and add some polynomial features\n",
    "x[y==0, 1] += 0.2\n",
    "x = np.hstack((x, x**2, (x[:, 0] * x[:, 1])[:, None], x**3))\n",
    "\n",
    "\n",
    "# Train-test split\n",
    "x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
    "    x, y, test_size=test_size / (n_batches * batchsize + test_size), random_state=seed\n",
    ")\n",
    "\n",
    "\n",
    "# Assign users randomly to each set after the split\n",
    "user_train = np.random.randint(1, n_users + 1, size=len(x_train))\n",
    "user_test = np.random.randint(1, n_users + 1, size=len(x_test))\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "x_train = torch.from_numpy(x_train).float()\n",
    "x_test = torch.from_numpy(x_test).float()\n",
    "y_train = torch.from_numpy(y_train)\n",
    "y_test = torch.from_numpy(y_test)\n",
    "user_train = torch.from_numpy(user_train)\n",
    "user_test = torch.from_numpy(user_test)\n",
    "\n",
    "# Combine inputs and both labels into TensorDatasets\n",
    "dataset_train = torch.utils.data.TensorDataset(x_train, user_train, y_train)\n",
    "dataset_test = torch.utils.data.TensorDataset(x_test, user_test, y_test)\n",
    "\n",
    "# Create DataLoaders\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batchsize, shuffle=True)\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=batchsize, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "privacy_bounded_models = {}\n",
    "k_private_values = [1, 2, 5, 10, 20, 50, 100] \n",
    "for k in k_private_values:\n",
    "    path = \"path/to/model\"\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Linear(7, 128),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(128, 2),\n",
    "    )\n",
    "    bounded_model = agt.bounded_models.IntervalBoundedModel(model, trainable=True)\n",
    "    bounded_model.load_params(path)\n",
    "    privacy_bounded_models[k] = bounded_model\n",
    "\n",
    "# evaluate the fine-tuned model\n",
    "dataset_test_all = torch.utils.data.TensorDataset(x_test, y_test)\n",
    "accuracy = agt.test_metrics.test_accuracy(bounded_model, *dataset_test_all.tensors)\n",
    "print(f\"Fine-tuned model accuracy + certified bounds (all classes): {accuracy[0]:.2f} <= {accuracy[1]:.2f} <= {accuracy[2]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f2795c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset_test = torch.utils.data.TensorDataset(x_test, y_test)\n",
    "\n",
    "# Define the specific epsilon values\n",
    "# epsilon_values = [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000, 1000000, 10000000, 100000000, 1000000000, 10000000000, 100000000000, 1000000000000]\n",
    "\n",
    "epsilon_values = [0.001,\n",
    "                0.004,\n",
    "                0.016,\n",
    "                0.064,\n",
    "                0.128,\n",
    "                0.256,\n",
    "                0.512,\n",
    "                1.024,\n",
    "                2.048,\n",
    "                4.096,\n",
    "                8.192,\n",
    "                16.384,\n",
    "                32.768,\n",
    "                65.536,\n",
    "                262.144,\n",
    "                1048.576,\n",
    "                4194.304,\n",
    "                16777.216,\n",
    "                67108.864]\n",
    "\n",
    "# Store results for both normal MSE and global sensitivity-based MSE\n",
    "normal_mse_values = []\n",
    "global_sensitivity_mse_values = []\n",
    "no_privacy_mse_values = []\n",
    "\n",
    "# Loop over epsilon values and calculate the MSE for each\n",
    "for epsilon in epsilon_values:\n",
    "    # Calculate the noise level using AGT smooth sensitivity bounds\n",
    "    noise_level = agt.privacy_utils.get_calibrated_noise_level(\n",
    "        dataset_test.tensors[0], privacy_bounded_models, epsilon=epsilon, noise_type=\"cauchy\"\n",
    "    )\n",
    "    \n",
    "    ave = 0\n",
    "    num = 1000\n",
    "    for i in range(num):\n",
    "        ave += agt.privacy_utils.noisy_test_accuracy(\n",
    "            privacy_bounded_models[100], *dataset_test.tensors, noise_level=noise_level, noise_type=\"cauchy\"\n",
    "        )\n",
    "    acc = ave / (num)\n",
    "    \n",
    "    # Store normal MSE\n",
    "    normal_mse_values.append(acc)\n",
    "    \n",
    "\n",
    "    ave = 0\n",
    "    num = 1000\n",
    "    for i in range(num):\n",
    "        ave += agt.privacy_utils.noisy_test_accuracy(\n",
    "            privacy_bounded_models[100], *dataset_test.tensors, noise_level=6/epsilon, noise_type=\"cauchy\"\n",
    "        )\n",
    "    \n",
    "    acc = ave / (num)\n",
    "    # Store global sensitivity MSE\n",
    "    global_sensitivity_mse_values.append(acc)\n",
    "\n",
    "    no_privacy_mse = agt.privacy_utils.noisy_test_accuracy(\n",
    "            privacy_bounded_models[100], *dataset_test.tensors, noise_level=0, noise_type=\"none\"\n",
    "        ) \n",
    "\n",
    "    # no_privacy_mse = agt.test_metrics.test_accuracy(privacy_bounded_models[1], x_test, y_test)[1]\n",
    "    \n",
    "    # Store global sensitivity MSE\n",
    "    no_privacy_mse_values.append(no_privacy_mse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ad403d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Create the figure\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "# Plot MSE curves with enhanced styles\n",
    "sns.lineplot(x=epsilon_values, y=normal_mse_values, label=\"AGT Accuracy\", \n",
    "             marker='o', markersize=10, linestyle='--', color='royalblue', linewidth=3)\n",
    "\n",
    "sns.lineplot(x=epsilon_values, y=global_sensitivity_mse_values, label=\"Global Sensitivity Accuracy\", \n",
    "             marker='x', markersize=10, linestyle='--', color='crimson', linewidth=3)\n",
    "\n",
    "sns.lineplot(x=epsilon_values, y=no_privacy_mse_values, label=\"No Privacy Accuracy\", \n",
    "             marker='s', markersize=10, linestyle='-', color='seagreen', linewidth=3)\n",
    "\n",
    "# Log scale for both axes\n",
    "plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "\n",
    "# Axis labels and title\n",
    "plt.xlabel('Epsilon (Log Scale)', fontsize=30)\n",
    "plt.ylabel('Accuracy', fontsize=30)\n",
    "# plt.title('MSE vs Epsilon under Different Privacy Settings', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Legend and grid\n",
    "plt.legend(title='Accuracy Type', fontsize=20, title_fontsize=24, loc='best')\n",
    "plt.grid(True, which=\"both\", linestyle='--', linewidth=2)\n",
    "\n",
    "# Tidy up layout\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.tick_params(axis='both', labelsize=20) \n",
    "\n",
    "plt.grid(which='minor', visible=False) \n",
    "# Show plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

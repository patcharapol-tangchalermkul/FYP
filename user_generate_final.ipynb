{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dabb954",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "import sklearn.model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import abstract_gradient_training as agt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013b54a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Initialise the halfmoons training data.\"\"\"\n",
    "seed = 0\n",
    "batchsize = 10000  # number of samples per batch\n",
    "test_size = 5000\n",
    "n_users = 1000\n",
    "n_batches = 1  # number of batches per epoch\n",
    "n_epochs = 10  # number of epochs\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "# load the dataset\n",
    "x, y = sklearn.datasets.make_moons(noise=0.1, n_samples=n_batches*batchsize + test_size, random_state=seed)\n",
    "# to make it easier to train, we'll space the moons out a bit and add some polynomial features\n",
    "x[y==0, 1] += 0.2\n",
    "x = np.hstack((x, x**2, (x[:, 0] * x[:, 1])[:, None], x**3))\n",
    "\n",
    "\n",
    "# Train-test split\n",
    "x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
    "    x, y, test_size=test_size / (n_batches * batchsize + test_size), random_state=seed\n",
    ")\n",
    "\n",
    "\n",
    "# Assign users randomly to each set after the split\n",
    "user_train = np.random.randint(1, n_users + 1, size=len(x_train))\n",
    "user_test = np.random.randint(1, n_users + 1, size=len(x_test))\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "x_train = torch.from_numpy(x_train).float()\n",
    "x_test = torch.from_numpy(x_test).float()\n",
    "y_train = torch.from_numpy(y_train)\n",
    "y_test = torch.from_numpy(y_test)\n",
    "user_train = torch.from_numpy(user_train)\n",
    "user_test = torch.from_numpy(user_test)\n",
    "\n",
    "# Combine inputs and both labels into TensorDatasets\n",
    "dataset_train = torch.utils.data.TensorDataset(x_train, user_train, y_train)\n",
    "dataset_test = torch.utils.data.TensorDataset(x_test, user_test, y_test)\n",
    "\n",
    "# Create DataLoaders\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batchsize, shuffle=True)\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=batchsize, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e42f0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(agt)\n",
    "\"\"\"Let's train a logistic classifier on the halfmoons example above.\"\"\"\n",
    "# model = torch.nn.Sequential(torch.nn.Linear(7, 2))\n",
    "torch.manual_seed(1)\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(7, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(128, 2),\n",
    ")\n",
    "config = agt.AGTConfig(\n",
    "    fragsize=2000,\n",
    "    learning_rate=0.5,\n",
    "    n_epochs=n_epochs,\n",
    "    device=\"cuda:0\",\n",
    "    l2_reg=0.01,\n",
    "    k_private=1,\n",
    "    loss=\"cross_entropy\",\n",
    "    log_level=\"INFO\",\n",
    "    lr_decay=2.0,\n",
    "    clip_gamma=1.0,\n",
    "    lr_min=0.001,\n",
    "    optimizer=\"SGDM\", # we'll use SGD with momentum\n",
    "    optimizer_kwargs={\"momentum\": 0.9, \"nesterov\": True},\n",
    ")\n",
    "k_values = [1,2,5,10,20,50,100]  # using more values here will improve the guarantees AGT will give\n",
    "bounded_model_dict = {}  # we'll store our results for each value of 'k' as a dictionary from 'k' to the bounded model\n",
    "\n",
    "for k_private in k_values:\n",
    "    config.k_private=k_private\n",
    "    torch.manual_seed(seed)\n",
    "    bounded_model = agt.bounded_models.IntervalBoundedModel(model)\n",
    "    bounded_model = agt.privacy_certified_training_user_level(bounded_model, config, dataloader_train, dataloader_test)\n",
    "    bounded_model_dict[k_private] = bounded_model\n",
    "    \n",
    "    # as a metric, compute the number of predictions in the test set certified at this value of k_private\n",
    "    certified_preds = agt.test_metrics.certified_predictions(bounded_model, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60807be",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in k_values:\n",
    "    path = \"path/to/save\"\n",
    "    bounded_model_dict[k].save_params(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

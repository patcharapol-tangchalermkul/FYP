{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afc5ea04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x705c93dc0f10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import copy\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import tqdm\n",
    "import torchvision\n",
    "\n",
    "from typing import Literal\n",
    "\n",
    "import abstract_gradient_training as agt\n",
    "from abstract_gradient_training import AGTConfig\n",
    "from abstract_gradient_training.bounded_models import IntervalBoundedModel\n",
    "\n",
    "import uci_datasets  # python -m pip install git+https://github.com/treforevans/uci_datasets.git\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fa1ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "houseelectric dataset, N=2049280, d=11\n",
      "<uci_datasets.dataset.Dataset object at 0x705b195a7670>\n"
     ]
    }
   ],
   "source": [
    "batchsize = 1000000\n",
    "data = uci_datasets.Dataset(\"houseelectric\")\n",
    "print(data)\n",
    "x_train, y_train, x_test, y_test = data.get_split(split=0)\n",
    "\n",
    "# Normalise the features and labels\n",
    "x_train_mu, x_train_std = x_train.mean(axis=0), x_train.std(axis=0)\n",
    "x_train = (x_train - x_train_mu) / x_train_std\n",
    "x_test = (x_test - x_train_mu) / x_train_std\n",
    "y_train_min, y_train_range = y_train.min(axis=0), y_train.max(axis=0) - y_train.min(axis=0)\n",
    "y_train = (y_train - y_train_min) / y_train_range\n",
    "y_test = (y_test - y_train_min) / y_train_range\n",
    "\n",
    "# Determine number of samples to keep (45%)\n",
    "num_samples = x_train.shape[0]\n",
    "keep_size = int(num_samples * 0.50)\n",
    "# Subset the training data\n",
    "x_train = x_train[:keep_size]\n",
    "y_train = y_train[:keep_size]\n",
    "\n",
    "# Form datasets and dataloaders\n",
    "train_data = torch.utils.data.TensorDataset(torch.from_numpy(x_train).float(), torch.from_numpy(y_train).float())\n",
    "test_data = torch.utils.data.TensorDataset(torch.from_numpy(x_test).float(), torch.from_numpy(y_test).float())\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batchsize, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "061ff025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batchsize = 1000000\n",
    "# # configure the training parameters\n",
    "# nominal_config = agt.AGTConfig(\n",
    "#     fragsize=20000,\n",
    "#     learning_rate=0.005,\n",
    "#     epsilon=0.01,\n",
    "#     k_private=1,\n",
    "#     n_epochs=1,\n",
    "#     device=\"cuda:0\",\n",
    "#     loss=\"mse\",\n",
    "#     log_level=\"DEBUG\",\n",
    "#     optimizer=\"SGDM\", # we'll use SGD with momentum\n",
    "#     optimizer_kwargs={\"momentum\": 0.9, \"nesterov\": True},\n",
    "# )\n",
    "\n",
    "# set up the AGT configuration\n",
    "nominal_config = AGTConfig(\n",
    "    fragsize=2000,\n",
    "    learning_rate=0.25,\n",
    "    n_epochs=10,\n",
    "    device=\"cuda:1\",\n",
    "    l2_reg=0.01,\n",
    "    k_private=1,\n",
    "    loss=\"mse\",\n",
    "    log_level=\"DEBUG\",\n",
    "    lr_decay=2.0,\n",
    "    clip_gamma=1.0,\n",
    "    lr_min=0.001,\n",
    "    optimizer=\"SGDM\", # we'll use SGD with momentum\n",
    "    optimizer_kwargs={\"momentum\": 0.9, \"nesterov\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a402b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[AGT] [INFO    ] [14:47:34] =================== Starting Privacy Certified Training ===================\n",
      "[AGT] [DEBUG   ] [14:47:34] \tOptimizer params: n_epochs=10, learning_rate=0.25, l1_reg=0.0, l2_reg=0.01\n",
      "[AGT] [DEBUG   ] [14:47:34] \tLearning rate schedule: lr_decay=2.0, lr_min=0.001\n",
      "[AGT] [DEBUG   ] [14:47:34] \tGradient clipping: gamma=1.0, method=clamp\n",
      "[AGT] [DEBUG   ] [14:47:34] \tPrivacy parameter: k_private=1\n",
      "[AGT] [INFO    ] [14:47:34] Starting epoch 1\n",
      "[AGT] [DEBUG   ] [14:47:44] Initialising dataloader batchsize to 1000000\n",
      "[AGT] [INFO    ] [14:47:44] Batch 1. Loss (mse): 0.346 <= 0.346 <= 0.346\n",
      "[AGT] [DEBUG   ] [14:47:45] Violated bound in validate_interval: 1.37e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:47:45] Violated bound in validate_interval: 1.13e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:47:46] Violated bound in validate_interval: 1.27e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:47:46] Violated bound in validate_interval: 1.28e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:47:47] Violated bound in validate_interval: 1.46e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:47:47] Violated bound in validate_interval: 1.49e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:47:48] Violated bound in validate_interval: 1.62e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:47:48] Violated bound in validate_interval: 1.58e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:47:48] Violated bound in validate_interval: 1.19e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:47:48] Violated bound in validate_interval: 1.16e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:47:49] Violated bound in validate_interval: 1.01e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:47:50] Violated bound in validate_interval: 1.61e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:47:50] Violated bound in validate_interval: 1.01e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:47:50] Violated bound in validate_interval: 1.19e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:47:51] Violated bound in validate_interval: 1.80e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:47:52] Violated bound in validate_interval: 1.19e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:47:52] Violated bound in validate_interval: 2.06e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:47:52] Violated bound in validate_interval: 1.64e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:47:54] Violated bound in validate_interval: 1.27e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:47:54] Violated bound in validate_interval: 1.55e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:47:54] Violated bound in validate_interval: 1.01e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:47:54] Violated bound in validate_interval: 1.07e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:47:54] Violated bound in validate_interval: 1.36e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:47:55] Violated bound in validate_interval: 1.25e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:47:56] Violated bound in validate_interval: 1.30e-06 (grad bounds, private fragment (element 0))\n",
      "[AGT] [DEBUG   ] [14:47:56] Violated bound in validate_interval: 3.40e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:47:56] Violated bound in validate_interval: 1.13e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:47:57] Violated bound in validate_interval: 1.13e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:47:57] Violated bound in validate_interval: 1.25e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:47:58] Violated bound in validate_interval: 1.13e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:47:58] Violated bound in validate_interval: 1.85e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:47:58] Violated bound in validate_interval: 1.31e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:47:58] Violated bound in validate_interval: 1.55e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:47:58] Violated bound in validate_interval: 1.85e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:47:58] Violated bound in validate_interval: 1.37e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:00] Violated bound in validate_interval: 2.68e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:00] Violated bound in validate_interval: 1.37e-06 (grad bounds, private fragment (element 0))\n",
      "[AGT] [DEBUG   ] [14:48:01] Violated bound in validate_interval: 1.55e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:01] Violated bound in validate_interval: 1.13e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:01] Violated bound in validate_interval: 1.46e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:01] Violated bound in validate_interval: 1.13e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:02] Violated bound in validate_interval: 1.01e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [ERROR   ] [14:48:02] Violated bound in validate_interval: 7.99e-02 (grad bounds, private fragment (element 0))\n",
      "[AGT] [ERROR   ] [14:48:02] Violated bound in validate_interval: 4.60e-02 (grad bounds, private fragment (element 1))\n",
      "[AGT] [DEBUG   ] [14:48:03] Violated bound in validate_interval: 1.01e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:04] Violated bound in validate_interval: 2.13e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:04] Violated bound in validate_interval: 1.43e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:04] Violated bound in validate_interval: 1.55e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:04] Violated bound in validate_interval: 1.24e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:05] Violated bound in validate_interval: 1.13e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:07] Violated bound in validate_interval: 1.25e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:08] Violated bound in validate_interval: 1.25e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:09] Violated bound in validate_interval: 1.25e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:09] Violated bound in validate_interval: 1.07e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:09] Violated bound in validate_interval: 1.31e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:09] Violated bound in validate_interval: 1.07e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:09] Violated bound in validate_interval: 1.19e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:11] Violated bound in validate_interval: 1.13e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:11] Violated bound in validate_interval: 1.19e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:12] Violated bound in validate_interval: 1.35e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:13] Violated bound in validate_interval: 1.25e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:15] Violated bound in validate_interval: 1.55e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:16] Violated bound in validate_interval: 1.07e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:16] Violated bound in validate_interval: 1.25e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:16] Violated bound in validate_interval: 1.25e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:17] Violated bound in validate_interval: 1.53e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:17] Violated bound in validate_interval: 1.19e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:17] Violated bound in validate_interval: 1.01e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:18] Violated bound in validate_interval: 1.16e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:18] Violated bound in validate_interval: 1.01e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:18] Violated bound in validate_interval: 1.37e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:18] Violated bound in validate_interval: 1.19e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:19] Violated bound in validate_interval: 1.31e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:20] Violated bound in validate_interval: 1.07e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:20] Violated bound in validate_interval: 1.31e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:21] Violated bound in validate_interval: 1.07e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:21] Violated bound in validate_interval: 1.37e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:21] Violated bound in validate_interval: 1.25e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:22] Violated bound in validate_interval: 1.49e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:22] Violated bound in validate_interval: 1.13e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:23] Violated bound in validate_interval: 1.37e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:23] Violated bound in validate_interval: 1.07e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:23] Violated bound in validate_interval: 1.31e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:23] Violated bound in validate_interval: 1.07e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:24] Violated bound in validate_interval: 1.86e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:24] Violated bound in validate_interval: 1.49e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:24] Violated bound in validate_interval: 1.10e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:25] Violated bound in validate_interval: 1.07e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:25] Violated bound in validate_interval: 1.55e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:25] Violated bound in validate_interval: 3.05e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:26] Violated bound in validate_interval: 1.61e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:26] Violated bound in validate_interval: 1.37e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:27] Violated bound in validate_interval: 1.45e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:27] Violated bound in validate_interval: 1.31e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:27] Violated bound in validate_interval: 1.01e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:28] Violated bound in validate_interval: 1.62e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:28] Violated bound in validate_interval: 1.07e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:29] Violated bound in validate_interval: 1.25e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:29] Violated bound in validate_interval: 1.37e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:30] Violated bound in validate_interval: 1.55e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:30] Violated bound in validate_interval: 1.13e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:31] Violated bound in validate_interval: 1.79e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:31] Violated bound in validate_interval: 1.49e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:31] Violated bound in validate_interval: 1.10e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:32] Violated bound in validate_interval: 1.31e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:33] Violated bound in validate_interval: 1.15e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:33] Violated bound in validate_interval: 1.43e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:34] Violated bound in validate_interval: 1.19e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:34] Violated bound in validate_interval: 1.22e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:34] Violated bound in validate_interval: 1.45e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:35] Violated bound in validate_interval: 1.01e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:35] Violated bound in validate_interval: 1.31e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:35] Violated bound in validate_interval: 1.01e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:36] Violated bound in validate_interval: 1.85e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:36] Violated bound in validate_interval: 1.34e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:37] Violated bound in validate_interval: 1.43e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:37] Violated bound in validate_interval: 3.20e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:37] Violated bound in validate_interval: 3.28e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:38] Violated bound in validate_interval: 1.01e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:38] Violated bound in validate_interval: 1.31e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:38] Violated bound in validate_interval: 1.43e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:38] Violated bound in validate_interval: 1.01e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:38] Violated bound in validate_interval: 1.13e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:38] Violated bound in validate_interval: 1.43e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:39] Violated bound in validate_interval: 3.00e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:40] Violated bound in validate_interval: 1.31e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:41] Violated bound in validate_interval: 1.31e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:41] Violated bound in validate_interval: 1.10e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:41] Violated bound in validate_interval: 1.13e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:41] Violated bound in validate_interval: 1.79e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:41] Violated bound in validate_interval: 1.31e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:42] Violated bound in validate_interval: 1.19e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:42] Violated bound in validate_interval: 1.34e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:42] Violated bound in validate_interval: 1.01e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:43] Violated bound in validate_interval: 1.13e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:43] Violated bound in validate_interval: 1.16e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:44] Violated bound in validate_interval: 3.04e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:44] Violated bound in validate_interval: 1.97e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:45] Violated bound in validate_interval: 1.31e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:46] Violated bound in validate_interval: 1.19e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:46] Violated bound in validate_interval: 1.46e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:48] Violated bound in validate_interval: 1.25e-06 (grad bounds, private fragment (element 2))\n",
      "[AGT] [DEBUG   ] [14:48:56] Skipping batch 2 in epoch 1 (expected batchsize 1000000, got 844352)\n",
      "[AGT] [INFO    ] [14:48:56] Starting epoch 2\n",
      "[AGT] [INFO    ] [14:49:05] Batch 2. Loss (mse): 0.686 <= 0.686 <= 0.686\n",
      "  0%|          | 0/7 [02:36<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m bounded_model \u001b[38;5;241m=\u001b[39m IntervalBoundedModel(model, trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# dl_train = torch.utils.data.DataLoader(dataset_train, batch_size=batchsize, shuffle=True)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# run AGT\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[43magt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprivacy_certified_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbounded_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m privacy_bounded_models[k_private] \u001b[38;5;241m=\u001b[39m bounded_model\n\u001b[1;32m     23\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetcwd()\n",
      "File \u001b[0;32m/vol/bitbucket/pt321/.venv/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/pt321/.venv/lib/python3.10/site-packages/abstract_gradient_training/privacy.py:57\u001b[0m, in \u001b[0;36mprivacy_certified_training\u001b[0;34m(bounded_model, config, dl_train, dl_val, dl_public)\u001b[0m\n\u001b[1;32m     54\u001b[0m val_iterator \u001b[38;5;241m=\u001b[39m training_utils\u001b[38;5;241m.\u001b[39mdataloader_cycle(dl_val) \u001b[38;5;28;01mif\u001b[39;00m dl_val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# main training loop\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n, (batch, labels, batch_public, labels_public) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(training_iterator, \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     58\u001b[0m     config\u001b[38;5;241m.\u001b[39mon_iter_start_callback(bounded_model)\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# possibly terminate early\u001b[39;00m\n",
      "File \u001b[0;32m/vol/bitbucket/pt321/.venv/lib/python3.10/site-packages/abstract_gradient_training/training_utils.py:200\u001b[0m, in \u001b[0;36mdataloader_pair_wrapper\u001b[0;34m(dl_train, dl_aux, n_epochs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     data_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(dl_train, dl_aux)  \u001b[38;5;66;03m# note that zip will stop at the shortest iterator\u001b[39;00m\n\u001b[1;32m    199\u001b[0m t \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# possibly undefined loop variable\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t, ((batch, labels), (batch_aux, labels_aux)) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_iterator):\n\u001b[1;32m    201\u001b[0m     batchsize \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m batch_aux \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/vol/bitbucket/pt321/.venv/lib/python3.10/site-packages/abstract_gradient_training/training_utils.py:196\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# handle the case where there is no auxiliary dataloader by returning dummy values\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dl_aux \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m     data_iterator: Iterable \u001b[38;5;241m=\u001b[39m (((b, l), (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)) \u001b[38;5;28;01mfor\u001b[39;00m b, l \u001b[38;5;129;01min\u001b[39;00m dl_train)\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     data_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(dl_train, dl_aux)  \u001b[38;5;66;03m# note that zip will stop at the shortest iterator\u001b[39;00m\n",
      "File \u001b[0;32m/vol/bitbucket/pt321/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    714\u001b[0m ):\n",
      "File \u001b[0;32m/vol/bitbucket/pt321/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/vol/bitbucket/pt321/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/vol/bitbucket/pt321/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/vol/bitbucket/pt321/.venv/lib/python3.10/site-packages/torch/utils/data/dataset.py:211\u001b[0m, in \u001b[0;36mTensorDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/pt321/.venv/lib/python3.10/site-packages/torch/utils/data/dataset.py:211\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(tensor[index] \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# to use privacy-safe certificates, we need to run AGT for a range of k_private values\n",
    "\n",
    "# we'll just pick a reasonable range of k_private values. adding more values will increase the runtime\n",
    "# but also result in tighter privacy results. even a few values are sufficient to demonstrate tighter privacy\n",
    "\n",
    "k_private_values = [1, 2, 5, 10, 20, 50, 100] \n",
    "privacy_bounded_models = {}\n",
    "config = copy.deepcopy(nominal_config)\n",
    "# config.log_level = \"WARNING\"\n",
    "\n",
    "for k_private in tqdm.tqdm(k_private_values):\n",
    "    # update config\n",
    "    config.k_private = k_private\n",
    "    # form bounded model\n",
    "    torch.manual_seed(1)\n",
    "    # get the nn model\n",
    "    model = torch.nn.Sequential(torch.nn.Linear(11, 32), torch.nn.ReLU(), torch.nn.Linear(32, 1)).to(config.device)\n",
    "    bounded_model = IntervalBoundedModel(model, trainable=True)\n",
    "    # dl_train = torch.utils.data.DataLoader(dataset_train, batch_size=batchsize, shuffle=True)\n",
    "    # run AGT\n",
    "    agt.privacy_certified_training(bounded_model, config, train_loader, dl_val=test_loader)\n",
    "    privacy_bounded_models[k_private] = bounded_model\n",
    "    path = os.getcwd()\n",
    "    privacy_bounded_models[k_private].save_params(f\"{path}/uci_data/50/uci_k_{k_private}.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ac7303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from abstract_gradient_training.bounded_models import BoundedModel\n",
    "def noisy_test_mse(\n",
    "    model: torch.nn.Sequential | BoundedModel,\n",
    "    batch: torch.Tensor,\n",
    "    labels: torch.Tensor,\n",
    "    *,\n",
    "    noise_level: float | torch.Tensor = 0.0,\n",
    "    noise_type: str = \"laplace\",\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Given a pytorch (or bounded) model, calculate the prediction accuracy on a batch of the test set when adding the\n",
    "    specified noise to the predictions.\n",
    "    NOTE: For now, this function only supports binary classification via the noise + threshold dp mechanism. This\n",
    "          should be extended to support multi-class problems via the noisy-argmax mechanism in the future.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Sequential | BoundedModel): The model to evaluate.\n",
    "        batch (torch.Tensor): Input batch of data (shape [batchsize, ...]).\n",
    "        labels (torch.Tensor): Targets for the input batch (shape [batchsize, ]).\n",
    "        noise_level (float | torch.Tensor, optional): Noise level for privacy-preserving predictions using the laplace\n",
    "            mechanism. Can either be a float or a torch.Tensor of shape (batchsize, ).\n",
    "        noise_type (str, optional): Type of noise to add to the predictions, one of [\"laplace\", \"cauchy\"].\n",
    "\n",
    "    Returns:\n",
    "        float: The noisy accuracy of the model on the test set.\n",
    "    \"\"\"\n",
    "    # get the test batch and send it to the correct device\n",
    "    if isinstance(model, BoundedModel):\n",
    "        device = torch.device(model.device) if model.device != -1 else torch.device(\"cpu\")\n",
    "    else:\n",
    "        device = torch.device(next(model.parameters()).device)\n",
    "    batch = batch.to(device)\n",
    "\n",
    "    # validate the labels\n",
    "    if labels.dim() > 1:\n",
    "        labels = labels.squeeze()\n",
    "    labels = labels.to(device).type(torch.int64)\n",
    "    assert labels.dim() == 1, \"Labels must be of shape (batchsize, )\"\n",
    "\n",
    "    # validate the noise parameters and set up the distribution\n",
    "    assert noise_type in [\"laplace\", \"cauchy\"], f\"Noise type must be one of ['laplace', 'cauchy'], got {noise_type}\"\n",
    "    noise_level += 1e-7  # can't set distributions scale to zero\n",
    "    noise_level = torch.tensor(noise_level) if isinstance(noise_level, float) else noise_level\n",
    "    noise_level = noise_level.to(device).type(batch.dtype)  # type: ignore\n",
    "    noise_level = noise_level.expand(labels.size())\n",
    "    if noise_type == \"laplace\":\n",
    "        noise_distribution = torch.distributions.Laplace(0, noise_level)\n",
    "    else:\n",
    "        noise_distribution = torch.distributions.Cauchy(0, noise_level)\n",
    "\n",
    "    # # nominal, lower and upper bounds for the forward pass\n",
    "    # logit_n = model.forward(batch).squeeze()\n",
    "\n",
    "    # # transform 2-logit models to a single output\n",
    "    # if logit_n.shape[-1] == 2:\n",
    "    #     logit_n = logit_n[:, 1] - logit_n[:, 0]\n",
    "    # if logit_n.dim() > 1:\n",
    "    #     raise NotImplementedError(\"Noisy accuracy is not supported for multi-class classification.\")\n",
    "\n",
    "    # nominal, lower and upper bounds for the forward pass\n",
    "    y_n = model.forward(batch).squeeze()\n",
    "\n",
    "    # transform 2-logit models to a single output\n",
    "    if y_n.shape[-1] == 2:\n",
    "        y_n = y_n[:, 1] - y_n[:, 0]\n",
    "    if y_n.dim() > 1:\n",
    "        raise NotImplementedError(\"Noisy accuracy is not supported for multi-class classification.\")\n",
    "\n",
    "    # # apply noise + threshold dp mechanisim\n",
    "    # y_n = (logit_n > 0).to(torch.float32).squeeze()\n",
    "    # noise = noise_distribution.sample().to(y_n.device).squeeze()\n",
    "    # assert noise.shape == y_n.shape\n",
    "    # y_n = (y_n + noise) > 0.5\n",
    "    # accuracy = (y_n == labels).float().mean().item()\n",
    "\n",
    "    # apply noise + threshold dp mechanisim\n",
    "    noise = noise_distribution.sample().to(y_n.device).squeeze()\n",
    "    assert noise.shape == y_n.shape\n",
    "    y_n = y_n + noise\n",
    "    accuracy = F.mse_loss(y_n, labels.squeeze()).item()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cf0cbb",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory models/18epochs does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m k_private_values:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mprivacy_bounded_models\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_params\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels/18epochs/uci_k\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mk\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/pt321/.venv/lib/python3.10/site-packages/abstract_gradient_training/bounded_models/base_model.py:254\u001b[0m, in \u001b[0;36mBoundedModel.save_params\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msave_params\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    248\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m    Save the model parameters to a pytorch file.\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \n\u001b[1;32m    251\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;124;03m        filename (str): Path to the file where the parameters should be saved.\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 254\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparam_n\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_param_n\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparam_l\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_param_l\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparam_u\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_param_u\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/pt321/.venv/lib/python3.10/site-packages/torch/serialization.py:943\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    940\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 943\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    944\u001b[0m         _save(\n\u001b[1;32m    945\u001b[0m             obj,\n\u001b[1;32m    946\u001b[0m             opened_zipfile,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    949\u001b[0m             _disable_byteorder_record,\n\u001b[1;32m    950\u001b[0m         )\n\u001b[1;32m    951\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/vol/bitbucket/pt321/.venv/lib/python3.10/site-packages/torch/serialization.py:810\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    809\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[0;32m--> 810\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/pt321/.venv/lib/python3.10/site-packages/torch/serialization.py:781\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    778\u001b[0m         torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mPyTorchFileWriter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream, _compute_crc32)\n\u001b[1;32m    779\u001b[0m     )\n\u001b[1;32m    780\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 781\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_compute_crc32\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Parent directory models/18epochs does not exist."
     ]
    }
   ],
   "source": [
    "for k in k_private_values:\n",
    "    privacy_bounded_models[k].save_params(f\"models/18epochs/uci_k{k}.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990b453a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2549, 0.2549, 0.2549,  ..., 0.2549, 0.2549, 0.2549], device='cuda:0')\n",
      "1.588772794591271\n",
      "Accuracy using AGT smooth sensitivity bounds: 325584.03\n",
      "Average MSE is 190.5872059983658\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import privacy_utils_regression\n",
    "importlib.reload(privacy_utils_regression)\n",
    "\n",
    "epsilon = 1.0\n",
    "# make privacy-safe predictions using the smooth sensitivity bounds from AGT\n",
    "noise_level = privacy_utils_regression.get_calibrated_noise_level(\n",
    "    test_data.tensors[0], privacy_bounded_models, min_bound=0, max_bound=10000, epsilon=epsilon, noise_type=\"cauchy\" \n",
    ")\n",
    "print(noise_level)\n",
    "accuracy = noisy_test_mse(\n",
    "    bounded_model, *test_data.tensors, noise_level=noise_level, noise_type=\"cauchy\"\n",
    ")\n",
    "print(accuracy / len(test_data))\n",
    "print(f\"Accuracy using AGT smooth sensitivity bounds: {accuracy:.2f}\")\n",
    "\n",
    "ave = 0\n",
    "num = 10000\n",
    "for i in range(num):\n",
    "    ave += noisy_test_mse(\n",
    "        bounded_model, *test_data.tensors, noise_level=noise_level, noise_type=\"cauchy\"\n",
    "    )\n",
    "print(f\"Average MSE is {ave / (num * len(test_data))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

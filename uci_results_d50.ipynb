{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8ded33",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import copy\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import tqdm\n",
    "import torchvision\n",
    "\n",
    "from typing import Literal\n",
    "\n",
    "import abstract_gradient_training as agt\n",
    "from abstract_gradient_training import AGTConfig\n",
    "from abstract_gradient_training.bounded_models import IntervalBoundedModel\n",
    "\n",
    "import uci_datasets  # python -m pip install git+https://github.com/treforevans/uci_datasets.git\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "import importlib\n",
    "import privacy_utils_regression\n",
    "importlib.reload(privacy_utils_regression)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880c6ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 1000000\n",
    "data = uci_datasets.Dataset(\"houseelectric\")\n",
    "x_train, y_train, x_test, y_test = data.get_split(split=0)\n",
    "# Normalise the features and labels\n",
    "x_train_mu, x_train_std = x_train.mean(axis=0), x_train.std(axis=0)\n",
    "x_train = (x_train - x_train_mu) / x_train_std\n",
    "x_test = (x_test - x_train_mu) / x_train_std\n",
    "y_train_min, y_train_range = y_train.min(axis=0), y_train.max(axis=0) - y_train.min(axis=0)\n",
    "y_train = (y_train - y_train_min) / y_train_range\n",
    "y_test = (y_test - y_train_min) / y_train_range\n",
    "\n",
    "# Form datasets and dataloaders\n",
    "train_data = torch.utils.data.TensorDataset(torch.from_numpy(x_train).float(), torch.from_numpy(y_train).float())\n",
    "test_data = torch.utils.data.TensorDataset(torch.from_numpy(x_test).float(), torch.from_numpy(y_test).float())\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batchsize, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d5a0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from abstract_gradient_training.bounded_models import BoundedModel\n",
    "def noisy_test_mse(\n",
    "    model: torch.nn.Sequential | BoundedModel,\n",
    "    batch: torch.Tensor,\n",
    "    labels: torch.Tensor,\n",
    "    noise_level: float | torch.Tensor = 0.0,\n",
    "    noise_type: str = \"laplace\",\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Given a pytorch (or bounded) model, calculate the prediction accuracy on a batch of the test set when adding the\n",
    "    specified noise to the predictions.\n",
    "    NOTE: For now, this function only supports binary classification via the noise + threshold dp mechanism. This\n",
    "          should be extended to support multi-class problems via the noisy-argmax mechanism in the future.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Sequential | BoundedModel): The model to evaluate.\n",
    "        batch (torch.Tensor): Input batch of data (shape [batchsize, ...]).\n",
    "        labels (torch.Tensor): Targets for the input batch (shape [batchsize, ]).\n",
    "        noise_level (float | torch.Tensor, optional): Noise level for privacy-preserving predictions using the laplace\n",
    "            mechanism. Can either be a float or a torch.Tensor of shape (batchsize, ).\n",
    "        noise_type (str, optional): Type of noise to add to the predictions, one of [\"laplace\", \"cauchy\"].\n",
    "\n",
    "    Returns:\n",
    "        float: The noisy accuracy of the model on the test set.\n",
    "    \"\"\"\n",
    "    # get the test batch and send it to the correct device\n",
    "    if isinstance(model, BoundedModel):\n",
    "        device = torch.device(model.device) if model.device != -1 else torch.device(\"cpu\")\n",
    "    else:\n",
    "        device = torch.device(next(model.parameters()).device)\n",
    "    batch = batch.to(device)\n",
    "    \n",
    "    # validate the labels\n",
    "    if labels.dim() > 1:\n",
    "        labels = labels.squeeze()\n",
    "        \n",
    "    labels = labels.to(device).type(torch.float64)\n",
    "    assert labels.dim() == 1, \"Labels must be of shape (batchsize, )\"\n",
    "\n",
    "    if noise_type in [\"none\"]:\n",
    "        # nominal, lower and upper bounds for the forward pass\n",
    "        y_n = model.forward(batch).squeeze()\n",
    "        return F.mse_loss(y_n, labels.squeeze()).item()\n",
    "\n",
    "    # validate the noise parameters and set up the distribution\n",
    "    assert noise_type in [\"laplace\", \"cauchy\"], f\"Noise type must be one of ['laplace', 'cauchy'], got {noise_type}\"\n",
    "    noise_level += 1e-7  # can't set distributions scale to zero\n",
    "    noise_level = torch.tensor(noise_level) if isinstance(noise_level, float) else noise_level\n",
    "    noise_level = noise_level.to(device).type(batch.dtype)  # type: ignore\n",
    "    noise_level = noise_level.expand(labels.size())\n",
    "    if noise_type == \"laplace\":\n",
    "        noise_distribution = torch.distributions.Laplace(0, noise_level)\n",
    "    else:\n",
    "        noise_distribution = torch.distributions.Cauchy(0, noise_level)\n",
    "\n",
    "    # nominal, lower and upper bounds for the forward pass\n",
    "    y_n = model.forward(batch).squeeze()\n",
    "\n",
    "    # transform 2-logit models to a single output\n",
    "    if y_n.shape[-1] == 2:\n",
    "        y_n = y_n[:, 1] - y_n[:, 0]\n",
    "    if y_n.dim() > 1:\n",
    "        raise NotImplementedError(\"Noisy accuracy is not supported for multi-class classification.\")\n",
    "\n",
    "    # apply noise + threshold dp mechanisim\n",
    "    noise = noise_distribution.sample().to(y_n.device).squeeze()\n",
    "    assert noise.shape == y_n.shape\n",
    "    y_n = y_n + noise\n",
    "    accuracy = F.mse_loss(y_n, labels.squeeze()).item()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08da7ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 25\n",
    "epochs = 10\n",
    "layer_size = 128\n",
    "\n",
    "privacy_bounded_models = {}\n",
    "k_private_values = [1, 2, 5, 10, 20, 50, 100] \n",
    "for k in k_private_values:\n",
    "    path = \"path/to/model\"\n",
    "    model = torch.nn.Sequential(torch.nn.Linear(11, layer_size), torch.nn.ReLU(), torch.nn.Linear(layer_size, 1))\n",
    "    bounded_model = IntervalBoundedModel(model, trainable=True)\n",
    "    bounded_model.load_params(path)\n",
    "    privacy_bounded_models[k] = bounded_model\n",
    "# evaluate the fine-tuned model\n",
    "accuracy = agt.test_metrics.test_mse(bounded_model, *test_data.tensors)\n",
    "print(f\"Fine-tuned model accuracy + certified bounds (all classes): {accuracy[2]:.2f} <= {accuracy[1]:.2f} <= {accuracy[1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4872d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define the specific epsilon values\n",
    "epsilon_values = [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000, 1000000, 10000000, 100000000, 1000000000, 10000000000, 100000000000, 1000000000000]\n",
    "\n",
    "# Store results for both normal MSE and global sensitivity-based MSE\n",
    "normal_mse_values = []\n",
    "global_sensitivity_mse_values = []\n",
    "no_privacy_mse_values = []\n",
    "\n",
    "# Loop over epsilon values and calculate the MSE for each\n",
    "for epsilon in epsilon_values:\n",
    "    # Calculate the noise level using AGT smooth sensitivity bounds\n",
    "    noise_level = privacy_utils_regression.get_calibrated_noise_level(\n",
    "        test_data.tensors[0], privacy_bounded_models, min_bound=0, max_bound=1, epsilon=epsilon, noise_type=\"cauchy\"\n",
    "    )\n",
    "    \n",
    "    ave = 0\n",
    "    num = 3000\n",
    "    for i in range(num):\n",
    "        ave += noisy_test_mse(\n",
    "            bounded_model, *test_data.tensors, noise_level=noise_level, noise_type=\"cauchy\"\n",
    "        )\n",
    "    normal_mse = ave / (num * len(test_data))\n",
    "    \n",
    "    # Store normal MSE\n",
    "    normal_mse_values.append(normal_mse)\n",
    "    \n",
    "\n",
    "    ave = 0\n",
    "    num = 3000\n",
    "    for i in range(num):\n",
    "        ave += noisy_test_mse(\n",
    "            bounded_model, *test_data.tensors, noise_level=6/epsilon, noise_type=\"cauchy\"\n",
    "        )\n",
    "    \n",
    "    global_mse = ave / (num * len(test_data))\n",
    "    # Store global sensitivity MSE\n",
    "    global_sensitivity_mse_values.append(global_mse)\n",
    "\n",
    "    no_privacy_mse = noisy_test_mse(\n",
    "            bounded_model, *test_data.tensors, noise_level=0, noise_type=\"none\"\n",
    "        ) / len(test_data)\n",
    "    # Store global sensitivity MSE\n",
    "    no_privacy_mse_values.append(no_privacy_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a6f819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a Seaborn theme\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Create the figure\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "# Plot MSE curves with enhanced styles\n",
    "sns.lineplot(x=epsilon_values, y=normal_mse_values, label=\"AGT MSE\", \n",
    "             marker='o', markersize=10, linestyle='--', color='royalblue', linewidth=3)\n",
    "\n",
    "sns.lineplot(x=epsilon_values, y=global_sensitivity_mse_values, label=\"Global Sensitivity MSE\", \n",
    "             marker='x', markersize=10, linestyle='--', color='crimson', linewidth=3)\n",
    "\n",
    "sns.lineplot(x=epsilon_values, y=no_privacy_mse_values, label=\"No Privacy MSE\", \n",
    "             marker='s', markersize=10, linestyle='-', color='seagreen', linewidth=3)\n",
    "\n",
    "# Log scale for both axes\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "\n",
    "# Axis labels and title\n",
    "plt.xlabel('Epsilon (Log Scale)', fontsize=30)\n",
    "plt.ylabel('MSE (Log Scale)', fontsize=30)\n",
    "# plt.title('MSE vs Epsilon under Different Privacy Settings', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Legend and grid\n",
    "plt.legend(title='MSE Type', fontsize=20, title_fontsize=24, loc='best')\n",
    "plt.grid(True, which=\"both\", linestyle='--', linewidth=2)\n",
    "\n",
    "# Tidy up layout\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.ylim(1e-8, 1e10)\n",
    "\n",
    "plt.tick_params(axis='both', labelsize=20) \n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

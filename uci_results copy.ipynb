{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a8ded33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'privacy_utils_regression' from '/data/pt321/FYP/privacy_utils_regression.py'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import copy\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import tqdm\n",
    "import torchvision\n",
    "\n",
    "from typing import Literal\n",
    "\n",
    "import abstract_gradient_training as agt\n",
    "from abstract_gradient_training import AGTConfig\n",
    "from abstract_gradient_training.bounded_models import IntervalBoundedModel\n",
    "\n",
    "import uci_datasets  # python -m pip install git+https://github.com/treforevans/uci_datasets.git\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "import importlib\n",
    "import privacy_utils_regression\n",
    "importlib.reload(privacy_utils_regression)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "880c6ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "houseelectric dataset, N=2049280, d=11\n",
      "<uci_datasets.dataset.Dataset object at 0x777207d74a30>\n",
      "[[  8.2875    0.54557   1.5752  ...  -1.1219   -0.29852  -5.4584 ]\n",
      " [ -6.7125   -5.4544   -0.42476 ...  -1.1219   -1.2985   -6.4584 ]\n",
      " [  5.2875   -4.4544    0.57524 ...  -1.1219   -1.2985   -6.4584 ]\n",
      " ...\n",
      " [-10.712    -0.45443  -0.42476 ...  -1.1219   -1.2985   10.542  ]\n",
      " [ 15.288    -3.4544    0.57524 ...  -1.1219   -1.2985   11.542  ]\n",
      " [  8.2875    3.5456   -1.4248  ...  -1.1219   -1.2985   10.542  ]]\n"
     ]
    }
   ],
   "source": [
    "batchsize = 1000000\n",
    "data = uci_datasets.Dataset(\"houseelectric\")\n",
    "print(data)\n",
    "x_train, y_train, x_test, y_test = data.get_split(split=0)\n",
    "print(x_train)\n",
    "# Normalise the features and labels\n",
    "x_train_mu, x_train_std = x_train.mean(axis=0), x_train.std(axis=0)\n",
    "x_train = (x_train - x_train_mu) / x_train_std\n",
    "x_test = (x_test - x_train_mu) / x_train_std\n",
    "y_train_min, y_train_range = y_train.min(axis=0), y_train.max(axis=0) - y_train.min(axis=0)\n",
    "y_train = (y_train - y_train_min) / y_train_range\n",
    "y_test = (y_test - y_train_min) / y_train_range\n",
    "\n",
    "# Form datasets and dataloaders\n",
    "train_data = torch.utils.data.TensorDataset(torch.from_numpy(x_train).float(), torch.from_numpy(y_train).float())\n",
    "test_data = torch.utils.data.TensorDataset(torch.from_numpy(x_test).float(), torch.from_numpy(y_test).float())\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batchsize, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0d5a0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from abstract_gradient_training.bounded_models import BoundedModel\n",
    "def noisy_test_mse(\n",
    "    model: torch.nn.Sequential | BoundedModel,\n",
    "    batch: torch.Tensor,\n",
    "    labels: torch.Tensor,\n",
    "    noise_level: float | torch.Tensor = 0.0,\n",
    "    noise_type: str = \"laplace\",\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Given a pytorch (or bounded) model, calculate the prediction accuracy on a batch of the test set when adding the\n",
    "    specified noise to the predictions.\n",
    "    NOTE: For now, this function only supports binary classification via the noise + threshold dp mechanism. This\n",
    "          should be extended to support multi-class problems via the noisy-argmax mechanism in the future.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Sequential | BoundedModel): The model to evaluate.\n",
    "        batch (torch.Tensor): Input batch of data (shape [batchsize, ...]).\n",
    "        labels (torch.Tensor): Targets for the input batch (shape [batchsize, ]).\n",
    "        noise_level (float | torch.Tensor, optional): Noise level for privacy-preserving predictions using the laplace\n",
    "            mechanism. Can either be a float or a torch.Tensor of shape (batchsize, ).\n",
    "        noise_type (str, optional): Type of noise to add to the predictions, one of [\"laplace\", \"cauchy\"].\n",
    "\n",
    "    Returns:\n",
    "        float: The noisy accuracy of the model on the test set.\n",
    "    \"\"\"\n",
    "    # get the test batch and send it to the correct device\n",
    "    if isinstance(model, BoundedModel):\n",
    "        device = torch.device(model.device) if model.device != -1 else torch.device(\"cpu\")\n",
    "    else:\n",
    "        device = torch.device(next(model.parameters()).device)\n",
    "    batch = batch.to(device)\n",
    "    \n",
    "    # validate the labels\n",
    "    if labels.dim() > 1:\n",
    "        labels = labels.squeeze()\n",
    "        \n",
    "    labels = labels.to(device).type(torch.float64)\n",
    "    assert labels.dim() == 1, \"Labels must be of shape (batchsize, )\"\n",
    "\n",
    "    if noise_type in [\"none\"]:\n",
    "        # nominal, lower and upper bounds for the forward pass\n",
    "        y_n = model.forward(batch).squeeze()\n",
    "        return F.mse_loss(y_n, labels.squeeze()).item()\n",
    "\n",
    "    # validate the noise parameters and set up the distribution\n",
    "    assert noise_type in [\"laplace\", \"cauchy\"], f\"Noise type must be one of ['laplace', 'cauchy'], got {noise_type}\"\n",
    "    noise_level += 1e-7  # can't set distributions scale to zero\n",
    "    noise_level = torch.tensor(noise_level) if isinstance(noise_level, float) else noise_level\n",
    "    noise_level = noise_level.to(device).type(batch.dtype)  # type: ignore\n",
    "    noise_level = noise_level.expand(labels.size())\n",
    "    if noise_type == \"laplace\":\n",
    "        noise_distribution = torch.distributions.Laplace(0, noise_level)\n",
    "    else:\n",
    "        noise_distribution = torch.distributions.Cauchy(0, noise_level)\n",
    "\n",
    "    # nominal, lower and upper bounds for the forward pass\n",
    "    y_n = model.forward(batch).squeeze()\n",
    "\n",
    "    # transform 2-logit models to a single output\n",
    "    if y_n.shape[-1] == 2:\n",
    "        y_n = y_n[:, 1] - y_n[:, 0]\n",
    "    if y_n.dim() > 1:\n",
    "        raise NotImplementedError(\"Noisy accuracy is not supported for multi-class classification.\")\n",
    "\n",
    "    # apply noise + threshold dp mechanisim\n",
    "    noise = noise_distribution.sample().to(y_n.device).squeeze()\n",
    "    assert noise.shape == y_n.shape\n",
    "    y_n = y_n + noise\n",
    "    accuracy = F.mse_loss(y_n, labels.squeeze()).item()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86090b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# import privacy_utils_regression\n",
    "# importlib.reload(privacy_utils_regression)\n",
    "\n",
    "# for lr in [10, 25, 50, 75, 100]: \n",
    "#     for epochs in [10, 20, 30]:     \n",
    "#         print(f\"Learning rate: {lr/100}, Num epochs: {epochs} --\")\n",
    "#         privacy_bounded_models = {}\n",
    "#         k_private_values = [1, 2, 5, 10, 20, 50, 100] \n",
    "#         for k in k_private_values:\n",
    "#             model = torch.nn.Sequential(torch.nn.Linear(11, 64), torch.nn.ReLU(), torch.nn.Linear(64, 1))\n",
    "#             bounded_model = IntervalBoundedModel(model, trainable=True)\n",
    "#             bounded_model.load_params(f\"models/{lr}/{epochs}/uci_k{k}.model\")\n",
    "#             privacy_bounded_models[k] = bounded_model\n",
    "#         # evaluate the fine-tuned model\n",
    "#         accuracy = agt.test_metrics.test_mse(bounded_model, *test_data.tensors)\n",
    "#         print(f\"Fine-tuned model accuracy + certified bounds (all classes): {accuracy[0]:.2f} <= {accuracy[1]:.2f} <= {accuracy[2]:.2f}\")\n",
    "\n",
    "#         epsilon = 1.0\n",
    "#         # make privacy-safe predictions using the smooth sensitivity bounds from AGT\n",
    "#         noise_level = privacy_utils_regression.get_calibrated_noise_level(\n",
    "#             test_data.tensors[0], privacy_bounded_models, min_bound=0, max_bound=1, epsilon=epsilon, noise_type=\"cauchy\" \n",
    "#         )\n",
    "\n",
    "#         accuracy = noisy_test_mse(\n",
    "#             bounded_model, *test_data.tensors, noise_level=noise_level, noise_type=\"cauchy\"\n",
    "#         )\n",
    "#         print(accuracy / len(test_data))\n",
    "#         print(f\"Accuracy using AGT smooth sensitivity bounds: {accuracy:.2f}\")\n",
    "\n",
    "#         ave = 0\n",
    "#         num = 3000\n",
    "#         for i in range(num):\n",
    "#             ave += noisy_test_mse(\n",
    "#                 bounded_model, *test_data.tensors, noise_level=noise_level, noise_type=\"cauchy\"\n",
    "#             )\n",
    "#         print(f\"Average MSE is {ave / (num * len(test_data))}\")\n",
    "\n",
    "#         ave = 0\n",
    "#         num = 3000\n",
    "#         for i in range(num):\n",
    "#             ave += noisy_test_mse(\n",
    "#                 bounded_model, *test_data.tensors, noise_level=6, noise_type=\"cauchy\"\n",
    "#             )\n",
    "#         print(f\"Average MSE global sensitivity is {ave / (num * len(test_data))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08da7ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned model accuracy + certified bounds (all classes): 0.08 <= 0.03 <= 0.01\n",
      "0.010251522986528894\n",
      "Accuracy using AGT smooth sensitivity bounds: 2100.82\n",
      "Average MSE is 0.05045951608167406\n",
      "Average MSE global sensitivity is 594.0590947489654\n"
     ]
    }
   ],
   "source": [
    "lr = 25\n",
    "epochs = 10\n",
    "layer_size = 64\n",
    "\n",
    "privacy_bounded_models = {}\n",
    "k_private_values = [1, 2, 5, 10, 20, 50, 100] \n",
    "for k in k_private_values:\n",
    "    model = torch.nn.Sequential(torch.nn.Linear(11, layer_size), torch.nn.ReLU(), torch.nn.Linear(layer_size, 1))\n",
    "    bounded_model = IntervalBoundedModel(model, trainable=True)\n",
    "    bounded_model.load_params(f\"models/{layer_size}/uci_k_{k}.model\")\n",
    "    privacy_bounded_models[k] = bounded_model\n",
    "# evaluate the fine-tuned model\n",
    "accuracy = agt.test_metrics.test_mse(bounded_model, *test_data.tensors)\n",
    "print(f\"Fine-tuned model accuracy + certified bounds (all classes): {accuracy[0]:.2f} <= {accuracy[1]:.2f} <= {accuracy[2]:.2f}\")\n",
    "\n",
    "epsilon = 1.0\n",
    "# make privacy-safe predictions using the smooth sensitivity bounds from AGT\n",
    "noise_level = privacy_utils_regression.get_calibrated_noise_level(\n",
    "    test_data.tensors[0], privacy_bounded_models, min_bound=0, max_bound=1, epsilon=epsilon, noise_type=\"cauchy\" \n",
    ")\n",
    "\n",
    "accuracy = noisy_test_mse(\n",
    "    bounded_model, *test_data.tensors, noise_level=noise_level, noise_type=\"cauchy\"\n",
    ")\n",
    "print(accuracy / len(test_data))\n",
    "print(f\"Accuracy using AGT smooth sensitivity bounds: {accuracy:.2f}\")\n",
    "\n",
    "ave = 0\n",
    "num = 100\n",
    "for i in range(num):\n",
    "    ave += noisy_test_mse(\n",
    "        bounded_model, *test_data.tensors, noise_level=noise_level, noise_type=\"cauchy\"\n",
    "    )\n",
    "print(f\"Average MSE is {ave / (num * len(test_data))}\")\n",
    "\n",
    "ave = 0\n",
    "num = 100\n",
    "for i in range(num):\n",
    "    ave += noisy_test_mse(\n",
    "        bounded_model, *test_data.tensors, noise_level=6, noise_type=\"cauchy\"\n",
    "    )\n",
    "print(f\"Average MSE global sensitivity is {ave / (num * len(test_data))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4872d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define the specific epsilon values\n",
    "epsilon_values = [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000, 1000000, 10000000, 100000000, 1000000000, 10000000000, 100000000000, 1000000000000]\n",
    "\n",
    "# Store results for both normal MSE and global sensitivity-based MSE\n",
    "normal_mse_values = []\n",
    "global_sensitivity_mse_values = []\n",
    "no_privacy_mse_values = []\n",
    "\n",
    "# Loop over epsilon values and calculate the MSE for each\n",
    "for epsilon in epsilon_values:\n",
    "    # Calculate the noise level using AGT smooth sensitivity bounds\n",
    "    noise_level = privacy_utils_regression.get_calibrated_noise_level(\n",
    "        test_data.tensors[0], privacy_bounded_models, min_bound=0, max_bound=1, epsilon=epsilon, noise_type=\"cauchy\"\n",
    "    )\n",
    "    \n",
    "    ave = 0\n",
    "    num = 3000\n",
    "    for i in range(num):\n",
    "        ave += noisy_test_mse(\n",
    "            bounded_model, *test_data.tensors, noise_level=noise_level, noise_type=\"cauchy\"\n",
    "        )\n",
    "    normal_mse = ave / (num * len(test_data))\n",
    "    # print(f\"Average MSE is {ave / (num * len(test_data))}\")\n",
    "    \n",
    "    # Store normal MSE\n",
    "    normal_mse_values.append(normal_mse)\n",
    "    \n",
    "\n",
    "    ave = 0\n",
    "    num = 3000\n",
    "    for i in range(num):\n",
    "        ave += noisy_test_mse(\n",
    "            bounded_model, *test_data.tensors, noise_level=6/epsilon, noise_type=\"cauchy\"\n",
    "        )\n",
    "    \n",
    "    global_mse = ave / (num * len(test_data))\n",
    "    # Store global sensitivity MSE\n",
    "    global_sensitivity_mse_values.append(global_mse)\n",
    "\n",
    "    no_privacy_mse = noisy_test_mse(\n",
    "            bounded_model, *test_data.tensors, noise_level=0, noise_type=\"none\"\n",
    "        ) / len(test_data)\n",
    "    # Store global sensitivity MSE\n",
    "    no_privacy_mse_values.append(no_privacy_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a6f819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a Seaborn theme\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Create the figure\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "# Plot MSE curves with enhanced styles\n",
    "sns.lineplot(x=epsilon_values, y=normal_mse_values, label=\"Normal MSE (AGT Sensitivity)\", \n",
    "             marker='o', color='royalblue', linewidth=2)\n",
    "\n",
    "sns.lineplot(x=epsilon_values, y=global_sensitivity_mse_values, label=\"Global Sensitivity MSE\", \n",
    "             marker='x', linestyle='--', color='crimson', linewidth=2)\n",
    "\n",
    "sns.lineplot(x=epsilon_values, y=no_privacy_mse_values, label=\"No Privacy MSE\", \n",
    "             marker='s', linestyle='-', color='seagreen', linewidth=2)\n",
    "\n",
    "# Log scale for both axes\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "\n",
    "# Axis labels and title\n",
    "plt.xlabel('Epsilon (Log Scale)', fontsize=14)\n",
    "plt.ylabel('MSE (Log Scale)', fontsize=14)\n",
    "plt.title('MSE vs Epsilon under Different Privacy Settings', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Legend and grid\n",
    "plt.legend(title='MSE Type', fontsize=12, title_fontsize=13, loc='best')\n",
    "plt.grid(True, which=\"both\", linestyle='--', linewidth=0.7)\n",
    "\n",
    "# Tidy up layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cd6191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.021144476703470028\n"
     ]
    }
   ],
   "source": [
    "no_privacy_mse = noisy_test_mse(\n",
    "        bounded_model, *test_data.tensors, noise_level=0, noise_type=\"none\"\n",
    "    )\n",
    "# Store global sensitivity MSE\n",
    "no_privacy_mse_values.append(no_privacy_mse)\n",
    "print(no_privacy_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cd6444",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (22,) and (23,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(epsilon_values, normal_mse_values, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNormal MSE (AGT Sensitivity)\u001b[39m\u001b[38;5;124m\"\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m\"\u001b[39m, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(epsilon_values, global_sensitivity_mse_values, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGlobal Sensitivity MSE\u001b[39m\u001b[38;5;124m\"\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m, linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m\"\u001b[39m, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepsilon_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno_privacy_mse_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNo Privacy MSE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgreen\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Set x-axis to logarithmic scale\u001b[39;00m\n\u001b[1;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mxscale(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/vol/bitbucket/pt321/.venv/lib/python3.10/site-packages/matplotlib/pyplot.py:3827\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3819\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   3820\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mplot\u001b[39m(\n\u001b[1;32m   3821\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3825\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3826\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[0;32m-> 3827\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3828\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3832\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3833\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/pt321/.venv/lib/python3.10/site-packages/matplotlib/axes/_axes.py:1777\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1534\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1535\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1536\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1776\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1777\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1778\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1779\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m/vol/bitbucket/pt321/.venv/lib/python3.10/site-packages/matplotlib/axes/_base.py:297\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, axes, data, return_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    296\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 297\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_kwargs\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/pt321/.venv/lib/python3.10/site-packages/matplotlib/axes/_base.py:494\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    491\u001b[0m     axes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 494\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    495\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    498\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (22,) and (23,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot both MSE curves\n",
    "plt.plot(epsilon_values, normal_mse_values, label=\"Normal MSE (AGT Sensitivity)\", color=\"blue\", marker='o')\n",
    "plt.plot(epsilon_values, global_sensitivity_mse_values, label=\"Global Sensitivity MSE\", color=\"red\", linestyle=\"--\", marker='x')\n",
    "plt.plot(epsilon_values, no_privacy_mse_values, label=\"No Privacy MSE\", color=\"green\")\n",
    "\n",
    "# Set x-axis to logarithmic scale\n",
    "plt.xscale('log')\n",
    "\n",
    "# Set y-axis to logarithmic scale\n",
    "plt.yscale('log')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Epsilon (Log Scale)')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('MSE vs Epsilon (Normal vs Global Sensitivity)')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.grid(True, which=\"both\", ls=\"--\")  # Add grid for both major and minor ticks\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

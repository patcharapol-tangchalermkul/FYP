{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dabb954",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "import sklearn.model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import abstract_gradient_training as agt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "013b54a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 9.5001e-02,  6.8417e-02,  9.0252e-03,  ...,  6.4997e-03,\n",
      "          8.5740e-04,  3.2026e-04],\n",
      "        [ 9.8377e-01, -4.7357e-01,  9.6781e-01,  ..., -4.6589e-01,\n",
      "          9.5210e-01, -1.0621e-01],\n",
      "        [-7.9546e-01,  5.5757e-01,  6.3276e-01,  ..., -4.4352e-01,\n",
      "         -5.0334e-01,  1.7334e-01],\n",
      "        ...,\n",
      "        [ 8.3354e-01,  6.2519e-01,  6.9480e-01,  ...,  5.2112e-01,\n",
      "          5.7914e-01,  2.4436e-01],\n",
      "        [ 8.8961e-03,  1.8451e-01,  7.9140e-05,  ...,  1.6414e-03,\n",
      "          7.0403e-07,  6.2816e-03],\n",
      "        [ 9.3713e-01,  5.1568e-01,  8.7822e-01,  ...,  4.8326e-01,\n",
      "          8.2301e-01,  1.3713e-01]])\n",
      "tensor([100,  36,   3,  ...,  87,  34,  73])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Initialise the halfmoons training data.\"\"\"\n",
    "seed = 0\n",
    "batchsize = 5000  # number of samples per batch\n",
    "test_size = 500\n",
    "n_users = 100\n",
    "# batchsize = 3  # number of samples per batch\n",
    "# test_size = 1\n",
    "# n_users = 1\n",
    "n_batches = 2  # number of batches per epoch\n",
    "n_epochs = 5  # number of epochs\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "# load the dataset\n",
    "x, y = sklearn.datasets.make_moons(noise=0.1, n_samples=n_batches*batchsize + test_size, random_state=seed)\n",
    "# to make it easier to train, we'll space the moons out a bit and add some polynomial features\n",
    "x[y==0, 1] += 0.2\n",
    "x = np.hstack((x, x**2, (x[:, 0] * x[:, 1])[:, None], x**3))\n",
    "# # perform a test-train split\n",
    "# x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
    "#     x, y, test_size=test_size / (n_batches*batchsize + test_size), random_state=seed\n",
    "# )\n",
    "\n",
    "# # convert into pytorch dataloaders\n",
    "# x_train, y_train = torch.from_numpy(x_train).float(), torch.from_numpy(y_train)\n",
    "# x_test, y_test = torch.from_numpy(x_test).float(), torch.from_numpy(y_test)\n",
    "# dataset_train = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "# dataset_test = torch.utils.data.TensorDataset(x_test, y_test)\n",
    "# dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batchsize, shuffle=True)\n",
    "# dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=batchsize, shuffle=False)\n",
    "\n",
    "\n",
    "# Assign random users 1â€“4 to each datapoint\n",
    "user_labels = np.random.randint(1, n_users + 1, size=len(x))\n",
    "\n",
    "# Train-test split\n",
    "x_train, x_test, y_train, y_test, user_train, user_test = sklearn.model_selection.train_test_split(\n",
    "    x, y, user_labels, test_size=test_size / (n_batches * batchsize + test_size), random_state=seed\n",
    ")\n",
    "\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "x_train = torch.from_numpy(x_train).float()\n",
    "x_test = torch.from_numpy(x_test).float()\n",
    "y_train = torch.from_numpy(y_train)\n",
    "y_test = torch.from_numpy(y_test)\n",
    "user_train = torch.from_numpy(user_train)\n",
    "user_test = torch.from_numpy(user_test)\n",
    "\n",
    "# Combine inputs and both labels into TensorDatasets\n",
    "dataset_train = torch.utils.data.TensorDataset(x_train, user_train, y_train)\n",
    "dataset_test = torch.utils.data.TensorDataset(x_test, user_test, y_test)\n",
    "\n",
    "# dataset_train = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "# dataset_test = torch.utils.data.TensorDataset(x_test, y_test)\n",
    "\n",
    "print(x_train)\n",
    "print(user_train)\n",
    "\n",
    "# Create DataLoaders\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batchsize, shuffle=True)\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=batchsize, shuffle=False)\n",
    "\n",
    "\n",
    "# for batch_idx, (inputs, user_labels, targets) in enumerate(dataloader_train):\n",
    "#     if batch_idx >= 2:  # Print only the first 2 batches\n",
    "#         break\n",
    "#     print(f\"Batch {batch_idx + 1}:\")\n",
    "#     print(\"Inputs:\")\n",
    "#     print(inputs)  # This will show the features (x)\n",
    "#     print(\"User Labels:\")\n",
    "#     print(user_labels)  # This will show the random user labels\n",
    "#     print(\"Targets:\")\n",
    "#     print(targets)  # This will show the target labels (y)\n",
    "#     print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8427ca0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2e42f0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch content: 6\n",
      "Shape of batch: torch.Size([5000, 7]), users: torch.Size([5000]), labels: torch.Size([5000])\n",
      "Unique users: tensor([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
      "         15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n",
      "         29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
      "         43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n",
      "         57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
      "         71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
      "         85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "         99, 100]), Inverse indices: tensor([18, 17, 10,  ...,  4, 31, 27])\n",
      "Shape of batch: torch.Size([5000, 7]), users: torch.Size([5000]), labels: torch.Size([5000])\n",
      "Unique users: tensor([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
      "         15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n",
      "         29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
      "         43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n",
      "         57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
      "         71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
      "         85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "         99, 100]), Inverse indices: tensor([62, 23, 49,  ..., 76, 31, 72])\n",
      "Shape of batch: torch.Size([5000, 7]), users: torch.Size([5000]), labels: torch.Size([5000])\n",
      "Unique users: tensor([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
      "         15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n",
      "         29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
      "         43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n",
      "         57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
      "         71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
      "         85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "         99, 100]), Inverse indices: tensor([ 0, 84, 44,  ..., 59, 37, 99])\n",
      "Shape of batch: torch.Size([5000, 7]), users: torch.Size([5000]), labels: torch.Size([5000])\n",
      "Unique users: tensor([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
      "         15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n",
      "         29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
      "         43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n",
      "         57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
      "         71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
      "         85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "         99, 100]), Inverse indices: tensor([56,  0, 42,  ..., 37, 83, 40])\n",
      "Shape of batch: torch.Size([5000, 7]), users: torch.Size([5000]), labels: torch.Size([5000])\n",
      "Unique users: tensor([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
      "         15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n",
      "         29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
      "         43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n",
      "         57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
      "         71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
      "         85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "         99, 100]), Inverse indices: tensor([57, 78, 64,  ..., 88, 44, 98])\n",
      "Shape of batch: torch.Size([5000, 7]), users: torch.Size([5000]), labels: torch.Size([5000])\n",
      "Unique users: tensor([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
      "         15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n",
      "         29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
      "         43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n",
      "         57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
      "         71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
      "         85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "         99, 100]), Inverse indices: tensor([ 1, 90, 13,  ..., 21, 77, 75])\n",
      "Shape of batch: torch.Size([5000, 7]), users: torch.Size([5000]), labels: torch.Size([5000])\n",
      "Unique users: tensor([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
      "         15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n",
      "         29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
      "         43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n",
      "         57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
      "         71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
      "         85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "         99, 100]), Inverse indices: tensor([16, 79,  7,  ..., 85, 87, 45])\n",
      "Shape of batch: torch.Size([5000, 7]), users: torch.Size([5000]), labels: torch.Size([5000])\n",
      "Unique users: tensor([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
      "         15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n",
      "         29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
      "         43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n",
      "         57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
      "         71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
      "         85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "         99, 100]), Inverse indices: tensor([26, 78, 49,  ..., 21, 86, 74])\n",
      "Shape of batch: torch.Size([5000, 7]), users: torch.Size([5000]), labels: torch.Size([5000])\n",
      "Unique users: tensor([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
      "         15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n",
      "         29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
      "         43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n",
      "         57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
      "         71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
      "         85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "         99, 100]), Inverse indices: tensor([43, 75, 95,  ...,  7, 80, 31])\n",
      "Certified Predictions at k=50: 0.00\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(agt)\n",
    "\"\"\"Let's train a logistic classifier on the halfmoons example above.\"\"\"\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(7, 128),  # First Linear layer: maps 7 input features to 2 output features\n",
    "    torch.nn.ReLU(),        # ReLU activation function applied to the output of the first linear layer\n",
    "    torch.nn.Linear(128, 2)   # Second Linear layer: maps the 2 features from ReLU to 1 final output feature\n",
    ")\n",
    "config = agt.AGTConfig(\n",
    "    learning_rate=0.5,\n",
    "    n_epochs=5,\n",
    "    loss=\"cross_entropy\",\n",
    "    log_level=\"WARNING\",\n",
    "    device=\"cuda:0\",\n",
    "    clip_gamma=0.1,\n",
    ")\n",
    "# k_values = [0, 1, 10, 20, 50, 100]  # using more values here will improve the guarantees AGT will give\n",
    "k_values = [50]  # using more values here will improve the guarantees AGT will give\n",
    "bounded_model_dict = {}  # we'll store our results for each value of 'k' as a dictionary from 'k' to the bounded model\n",
    "\n",
    "for k_private in k_values:\n",
    "    config.k_private=k_private\n",
    "    torch.manual_seed(seed)\n",
    "    bounded_model = agt.bounded_models.IntervalBoundedModel(model)\n",
    "    bounded_model = agt.privacy_certified_training_user_level(bounded_model, config, dataloader_train)\n",
    "    bounded_model_dict[k_private] = bounded_model\n",
    "    \n",
    "    # as a metric, compute the number of predictions in the test set certified at this value of k_private\n",
    "    certified_preds = agt.test_metrics.certified_predictions(bounded_model, x_test)\n",
    "    print(f\"Certified Predictions at k={k_private}: {certified_preds:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a2ea68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Free Accuracy: 0.86\n",
      "Smooth Sensitivity Accuracy: 0.85\n",
      "Global Sensitivity Accuracy: 0.58\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\"\"\"Let's use this set of bounded models to for better private prediction using the smooth sensitivity mechanism.\"\"\"\n",
    "\n",
    "epsilon = 0.5  # privacy loss\n",
    "noise_free_acc = agt.test_metrics.test_accuracy(bounded_model_dict[0], x_test, y_test)[0]\n",
    "\n",
    "# compute accuracy using the smooth sensitivity Cauchy mechanism\n",
    "smooth_sens_noise_level = agt.privacy_utils.get_calibrated_noise_level(\n",
    "    x_test, bounded_model_dict, epsilon, noise_type=\"cauchy\"\n",
    ")\n",
    "smooth_sens_acc = agt.privacy_utils.noisy_test_accuracy(\n",
    "    bounded_model_dict[0], x_test, y_test, noise_level=smooth_sens_noise_level, noise_type=\"cauchy\"\n",
    ")\n",
    "\n",
    "# compute accuracy when using the global sensitivity mechanism\n",
    "global_sens_acc = agt.privacy_utils.noisy_test_accuracy(\n",
    "    bounded_model_dict[0], x_test, y_test, noise_level=1.0 / epsilon\n",
    ")\n",
    "\n",
    "print(f\"Noise Free Accuracy: {noise_free_acc:.2f}\")\n",
    "print(f\"Smooth Sensitivity Accuracy: {smooth_sens_acc:.2f}\")\n",
    "print(f\"Global Sensitivity Accuracy: {global_sens_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a5e7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[AGT] [INFO    ] [03:30:35] =================== Starting Privacy Certified Training ===================\n",
      "[AGT] [INFO    ] [03:30:35] Starting epoch 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch content: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[AGT] [INFO    ] [03:30:35] Batch 1. Loss (accuracy): 0.460 <= 0.460 <= 0.460\n",
      "[AGT] [INFO    ] [03:30:36] Starting epoch 2\n",
      "[AGT] [INFO    ] [03:30:36] Batch 2. Loss (accuracy): 0.496 <= 0.498 <= 0.944\n",
      "[AGT] [INFO    ] [03:30:37] Batch 3. Loss (accuracy): 0.000 <= 0.896 <= 1.000\n",
      "[AGT] [INFO    ] [03:30:38] Final Eval. Loss (accuracy): 0.000 <= 0.898 <= 1.000\n",
      "[AGT] [INFO    ] [03:30:38] =================== Finished Privacy Certified Training ===================\n",
      "[AGT] [INFO    ] [03:30:38] =================== Starting Privacy Certified Training ===================\n",
      "[AGT] [INFO    ] [03:30:38] Starting epoch 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch content: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[AGT] [INFO    ] [03:30:38] Batch 1. Loss (accuracy): 0.460 <= 0.460 <= 0.460\n",
      "[AGT] [INFO    ] [03:30:39] Starting epoch 2\n",
      "[AGT] [INFO    ] [03:30:39] Batch 2. Loss (accuracy): 0.498 <= 0.498 <= 0.498\n",
      "[AGT] [INFO    ] [03:30:40] Batch 3. Loss (accuracy): 0.582 <= 0.782 <= 0.920\n",
      "[AGT] [INFO    ] [03:30:41] Final Eval. Loss (accuracy): 0.582 <= 0.912 <= 0.982\n",
      "[AGT] [INFO    ] [03:30:41] =================== Finished Privacy Certified Training ===================\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# \"\"\"Initialise a large model (which will be random here but would be a pre-trained model in practice).\"\"\"\n",
    "# model = torch.nn.Sequential(\n",
    "#     torch.nn.Linear(7, 128),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.Linear(128, 128),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.Linear(128, 128),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.Linear(128, 2)\n",
    "# )\n",
    "# config = agt.AGTConfig(\n",
    "#     learning_rate=0.5,\n",
    "#     n_epochs=2,\n",
    "#     loss=\"cross_entropy\",\n",
    "#     log_level=\"INFO\",\n",
    "#     device=\"cuda:0\",\n",
    "#     clip_gamma=0.1,\n",
    "#     k_private=10\n",
    "# )\n",
    "\n",
    "# # first try training the whole thing - observe that the certified accuracy goes to zero\n",
    "# bounded_model = agt.bounded_models.IntervalBoundedModel(model)\n",
    "# bounded_model = agt.privacy_certified_training_user_level(bounded_model, config, dataloader_train, dataloader_test)\n",
    "\n",
    "# # second, split the model into a fixed part and a trainable part\n",
    "# fixed_layers, trainable_layers = model[:4], model[4:]\n",
    "# # wrap both in bounded models, using the first as the 'transform' argument to the second\n",
    "# transform = agt.bounded_models.IntervalBoundedModel(fixed_layers, trainable=False)\n",
    "# bounded_model = agt.bounded_models.IntervalBoundedModel(trainable_layers, transform=transform)\n",
    "# # train the model\n",
    "# bounded_model = agt.privacy_certified_training_user_level(bounded_model, config, dataloader_train, dataloader_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
